\documentclass{article}
\usepackage{mathtools}
\usepackage[utf8]{inputenc}
\usepackage{tikz,pgfplots,filecontents,amsmath}
\pgfplotsset{compat=1.5}

\begin{filecontents}{data.dat}
 n   xn 
 0   1  
 1   0  
 2   0
 3   0
 4   0
 5   0
 6   0
 7   0
 8   0
\end{filecontents}

\title{Counting Submultiset Combinations}
\author{Charles Dunn}
\date{August 2018}

\usepackage{natbib}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{dsfont}
\usepackage{bm}
\usepackage{amssymb}
\usepackage{bbm}
\usepackage{breqn}
\usepackage{color}

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\setcounter{MaxMatrixCols}{13}

\newcommand{\Conv}{\mathop{\scalebox{1.5}{\raisebox{-0.2ex}{$\ast$}}}}%


\begin{document}

\maketitle

\section{Introduction}

Many games involve selecting a few items from a larger group. Examples include dealing hands from a deck in card games or selecting tiles in Scrabble. It is a common method of introducing randomness. To inform strategy or to formalize a process with random subset selection, it is useful to exhaustively count the number of combinations of a given number of items randomly selected from a group. Note that we are not considering the order of the selected items since games like Poker and Scrabble are agnostic to hand order; we are interested in the number of combinations, not the number of permutations.

Formally, the purpose of this paper is to derive an analytical solution and implement a fast algorithm for $\bm{C}(\bm{m})[k]$, the number of combinations of $k$ items selected without replacement from the multiset $S$ with multiplicity $\bm{m}$. 

It is worth noting that no constraints should be applied to $S$ in the final solution. The binomial coefficient (i.e. ``n choose k'') suffices as a solution to our problem only for sets without repeated elements\footnote{Sets do not account for repeated elements, while multisets can have multiple instances of the same type. Sets are a special case of multisets.}, but overcounts if there are any repeated (i.e. interchangeable) elements in $S$. An example of a set for which the binomial coefficient is sufficient is the standard deck of playing cards. One example of a multiset with repetition is the tiles in Scrabble, where there are twelve identical `E' tiles and various quantities of other tile types. Our desired solution for $\bm{C}(\bm{m})[k]$ will provide the correct value regardless of the structure of $S$.

In the conclusion, we will show the calculated values using our solution and implementation of $\bm{C}(\bm{m})[k]$ for the number of possible starting hands in Scrabble, Hanabi, and Mahjongg.

\section{Formalization}

Let $S$ be the full multiset of $n$ items from which a submultiset will be selected.
\begin{equation}
    n = \left | S \right | 
\end{equation} 
\begin{equation}
    S = \{ s_1, s_2, ..., s_n\}
\end{equation} 
Let $A$ be the unique set of $u$ item types from which $S$ is constructed. This is the set of all possible item types. Every item in $S$ is in $A$ exactly once.
\begin{equation}
    A = \{ a_1, a_2, ..., a_u\} = \bigcup_{s\in S} s
\end{equation} 
\begin{equation}
    u = \left | A \right | 
\end{equation} 
Let $\bm{m} \in \mathbb{Z}_{*}^{u}$ be the multiplicity of $S$. This is just a count of the number of occurrences of each item type in the full multiset $S$. That is, the $j$th element of $\bm{m}$, $m_j$, is the count of items in $S$ with item type $a_j \in A$.

To calculate $m_j$ from $S$, iterate over all elements of $S$ and increment the count for each item of type $a_j$.
\begin{equation}
    m_j = \sum_{s \in S} \mathbbm{1}_{a_j}(s) = \sum_{i = 1}^n \begin{cases}1 & s_i = a_j \\ 0 & \text{else} \end{cases}
\end{equation} 

Note that the number of unique item types in $S$ is just the size of the multiplicity.
\begin{equation}
    u = |\bm{m}|
\end{equation} 

We will use sub- and superscript notation to denote a range of $\bm{m}$. As an example, $\bm{m}_{1}^{u - 1}$ is all but the last element of $\bm{m}$.

\section{Analytical Solution}

To restate our goal, we are looking for an analytical solution for $C(\bm{m})[k] \in \mathbb{Z}_{*}$, the count of combinations of $k \in \mathbb{Z}$ items selected without replacement from a multiset with multiplicity $\bm{m} \in \mathbb{Z}_{+}^u$ of $u$ unique item types.

\subsection{Preparation}

 We will use induction to solve for $C(\bm{m})[k]$, but we must first prove two things: how to solve for $C(\bm{m})[k]$ from the combination of two disjoint multisets, and how to segment a multiset into disjoint submultisets.


% \begin{tikzpicture}
% \begin{axis}
% [%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     axis x line=bottom,
%     axis y line=middle,
%     axis equal image,
%     every axis x label={at={(current axis.right of origin)},anchor=north west},
%     every axis y label={at={(current axis.above origin)},anchor= north west},
%     xlabel={$k$},
%     ylabel={${C([])[k]}$},
%     xtick={0, 1, 2, 3, 4, 5, 6, 7, 8},
%     ymin=0,
%     ymax=1,
%     ytick={1},
% ]%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \addplot+[ycomb,black,thick] table [x={n}, y={xn}] {data.dat};
% \end{axis}
% \end{tikzpicture}

\subsubsection{Disjoint Multiset Union} \label{union}

We will show that combining two disjoint multisets results in a convolution of their combination counting functions.\footnote{Convolution is an incredibly powerful mathematical concept, and has applications in signal processing, statistics, algebra, machine learning, and more. It is worth researching if you have not encountered it before.} The convolution of two discrete functions $f[\cdot]$ and $g[\cdot]$ is represented as $(f * g)[\cdot]$.
\begin{equation}
     (f * g)[x] \equiv \sum_{\gamma=-\infty}^{\infty} f[\gamma]g[x - \gamma]
\end{equation}

Let $S_p$ and $S_q$ be two disjoint multisets we combine to form multiset $S$. Disjoint multisets have no elements in common. 
\begin{equation}
    \varnothing = S_p \cap S_q
\end{equation}
\begin{equation}
    S = S_p \uplus S_q
\end{equation}

As always, for any multiset $S_p$ we can derive the multiplicity $\bm{p}$, number of elements $n_p$, set of item types $A_p$, and number of item types $u_p$. The same notation holds for $S_q$.

$C(\bm{m}_p)[\cdot]$ is the combination count function for $S_p$ and $C(\bm{m}_q)[\cdot]$ is the combination count function for $S_q$. We will solve for $C(\bm{m})[\cdot]$, the combination count function for $S$, in terms of the other two functions.

For each combination of $k$ items from $A$, $k_p \in [0, k]$ items are from $A_p$ and $k_q\in [0, k]$ items are from $A_q$. Furthermore, the sum of items selected from the two multisets must equal the total number of items selected.
\begin{equation}
    k = k_p + k_q
\end{equation}

$C(\bm{m}_p)[\cdot]$ and $C(\bm{m}_q)[\cdot]$ are independent organizations; for each combination of items from $S_p$ counted by $C(\bm{m}_p)[k_p]$, there are exactly $C(\bm{m}_q)[k_q]$ combinations of the remaining items from $S_q$. Therefore, for a given $k_p$, the count of combinations of $k$ items from $S$ is simply the product of the two known combination counts.
\begin{equation}
    C(\bm{m}; k_p)[k] = C(\bm{m}_p)[k_p] \cdot C(\bm{m}_q)[k_q] = C(\bm{m}_p)[k_p] \cdot C(\bm{m}_q)[k - k_p]
\end{equation}

For any combination of $k$ items, $k_p$ is at least $0$ and at most $k$. The sum of the above equation over all values of $k_1$ exactly counts all combinations of $k$ items.
\begin{equation}
    C(\bm{m})[k] = \sum_{k_p = 0}^{k} C(\bm{m}; k_p)[k] = \sum_{k_p = 0}^{k} C(\bm{m}_p)[k_p] \cdot C(\bm{m}_q)[k - k_p]
\end{equation}

$C(\bm{m})[k]=0$ for any $k<0$, since there is no way to ever select a negative number of items for a multiset. Since $C(\bm{m}_p)[k_p] = 0$ when $k_p < 0$ and $C(\bm{m}_q)[k - k_1] = 0$ when $k_p > k$, we can make the sum infinite without affecting the value.
\begin{equation}
    C(\bm{m})[k] = \sum_{k_p = -\infty}^{\infty} C(\bm{m}_p)[k_p] \cdot C(\bm{m}_q)[k - k_p]
\end{equation}

This is the convolution of the two functions.
\begin{equation}
    C(\bm{m})[k] = (C(\bm{m}_p) * C(\bm{m}_q))[k]
\end{equation}

To summarize, we have proved that when joining two disjoint multisets, the resulting combination count is a convolution of the input combination counts.

\subsubsection{Disjoint Submultiset Segmentation} \label{segment}

The above result is only useful if we know how to create two disjoint submultisets from a multiset $S$. There are many ways to do this, but we will focus on creating a disjoint submultisets where one has only one item type. Specifically, let $S$ be the multiset with at least two item types for which we would like a combination count function. 
\begin{equation}
    S = \{a_1^{m_1}, a_2^{m_2}, ... a_u^{m_u}\}
\end{equation}
\begin{equation}
    u>1
\end{equation}

Let $S_p$ be the multiset containing all elements in $S$ of type $a_1$.
\begin{equation} \label{segment_eq1}
    S_p = \{a_1^{m_1}\}
\end{equation}

Let $S_q$ be a multiset containing all the remaining elements of $S$.
\begin{equation}
    S_q = S \setminus S_p
\end{equation}

Obviously, multisets $S_p$ and $S_q$ are disjoint, but their union covers the entire original set $S$.

The multiplicities of the resulting sets are easily defined. Let $\bm{p}$ and $\bm{q}$ be the respective multiplicities of multisets $S_p$ and $S_q$. $\bm{p}$ is just the first element of $\bm{m}$, which should be obvious from equation \ref{segment_eq1}. $\bm{q}$ is simply the remaining elements.
\begin{equation}
    \bm{p} = [m_1]
\end{equation}
\begin{equation}
    \bm{q} = \bm{m}_2^u
\end{equation}

Therefore, $\bm{m}$ is just the concatenation of $\bm{p}$ and $\bm{q}$.
\begin{equation}
    \bm{m} = [\bm{p}, \bm{q}]
\end{equation}

\subsection{Proof by Induction}

We can now demonstrate through inductive reasoning how to define a recursive solution for $C(\bm{m})[\cdot]$ for any multiset $S$.

\subsubsection{Base Case}

As with any proof by induction, we start with base cases, one of them trivial. 

If multiset $S$ is empty, there is exactly one combination of zero items that can be selected from it, and zero combinations of any other number of items. If $S$ is empty, $n=0$ and $u=0$.
\begin{equation}
    C(\bm{m})[k] = \delta_0[k] = \begin{cases}1 & k = 0 \\ 0 & \text{else}  \end{cases} \text{ if } u=0
\end{equation}

For reasons that will be obvious soon, we can express this case in terms of a rectangular function of width $n=0$.
\begin{equation}
    C(\bm{m})[k] = \delta_0[k] = \Pi_n[k] \text{ if } u=0
\end{equation}

The second trivial case is where $S$ has only one item type, so $u=1$. This is equivalent to $\bm{m}$ having only one element. Since $n$ is the number of items in the multiset, if $\bm{m}$ has only one element, it must be $n$. This simplicity means counting the possible combinations is relatively clear. If the entire multiset of $n$ items is composed of identical items, then there is exactly one combination of $k$ items if $k \leq n$ and exactly zero combinations otherwise.
\begin{equation}
    C(\bm{m})[k] = \Pi_n[k] = \begin{cases}1 & 0 \leq k \leq n \\ 0 & \text{else}  \end{cases}\text{ if } u = 1
\end{equation}

In both cases, when $S$ has zero or one item type, our solution for $C(\bm{m})[k]$ is the same, so we can combine them.
\begin{equation}
    C(\bm{m})[k] = \Pi_n[k] = \begin{cases}1 & 0 \leq k \leq n \\ 0 & \text{else}  \end{cases}\text{ if } u\leq 1
\end{equation}

\subsubsection{Inductive Step}

In all other cases, $S$ has at least two item types, and $\bm{m}$ has at least two elements. When this is the case, we can always break up $S$ into two disjoint submultisets, as shown in section \ref{segment}, and recombine their combination counting functions, as shown in section \ref{union}.
\begin{equation}
    C(\bm{m})[k] = (C([m_1]) * C(\bm{m}_2^u))[k]\text{ if } u>1
\end{equation}

\subsubsection{Recursive Solution}

We can now recursively define $C(\bm{m})[k]$ since we have a base case and an inductive step.
\begin{equation}
    C(\bm{m})[k] = \begin{cases}\Pi_n[k] & u \leq 1 \\
    (C([m_1]) * C(\bm{m}_2^u))[k] & \text{else} \end{cases}
\end{equation}

Note that we actually solved for the function regardless of $k$. This has implications for optimization when we implement the solution. \begin{equation} \label{rec}
    C(\bm{m}) = \begin{cases}\Pi_n & u \leq 1 \\
    C([m_1]) * C(\bm{m}_2^u) & \text{else} \end{cases}
\end{equation}

We have our first version of an analytical solution for the number of combinations of items from a multiset!

\subsection{Iterative Solution}

We would like to get our solution into a more practical form. To introduce some convenient notation, let $\Conv_{i=1}^N f_i$ be the convolution of the $N$ functions $f_1, f_2, ..., f_N$. 
\begin{equation}
    \Conv_{i=1}^N f_i = f_1 * f_2 * ... * f_N
\end{equation}
In the special case that $N=1$, we will just get the first function back.\footnote{This is all very similar to the better-known summation $\Sigma_{i=1}^N$ and product $\Pi_{i=1}^N$ notations.}
\begin{equation}
    \Conv_{i=1}^1 f_i = f_1
\end{equation}

If we perpetually replace the recursive parts of our previous solution, we arrive at a rather elegant one. The first part of the convolution in (\ref{rec}) is simply a rectangular function since it meets the condition that $u\leq 1$. The second will once again split the first element of $\bm{m}_2^u$ off from the rest.\footnote{This is not rigorous since have not constrained $u$ to be at least 3, but it is conceptually sound.} With one step down the recursion tree, we get the following.
\begin{equation}
    C(\bm{m}) = \begin{cases}\Pi_n & u \leq 1 \\
    \Pi_{m_1} * (C([m_2]) * C(\bm{m}_3^u)) & \text{else} \end{cases}
\end{equation}
It should now be clear that after repeated applications, we arrive at a long chain of convolved rectangular functions.
\begin{equation}
    C(\bm{m}) = \begin{cases}\Pi_n & u \leq 1 \\
    \Pi_{m_1} * (\Pi_{m_1} * (... * \Pi_{m_u})...)) & \text{else} \end{cases}
\end{equation}
Convolution is a linear operation is therefore associative.
\begin{equation}
    C(\bm{m}) = \begin{cases}\Pi_n & u \leq 1 \\
    \Pi_{m_1} * \Pi_{m_1} * ... * \Pi_{m_u} & \text{else} \end{cases}
\end{equation}
We can now apply our convenient notation, and revel in the fact that both cases collapse to one.
\begin{equation}
    C(\bm{m}) = \Conv_{i=1}^u \Pi_{m_i}
\end{equation}
This is a magnificently elegant analytical solution to a potentially ugly problem. It means that for any multiset with $u$ item types, regardless of its structure, we can solve for the number of combinations of any number of items simply by doing $u-1$ convolutions of $u$ rectangular functions.

\section{Implementation}

\pagebreak


Because $S_a$ and $S_b$ are disjoint, $C$ is simply the concatenation of $A$ and $B$.

\begin{equation}
    A = \{ \alpha_1, \alpha_2, ..., \alpha_{n_a}\}
\end{equation}

\begin{equation}
    B = \{ c_1, c_2, ..., c_{u_1}\}
\end{equation}

\begin{equation}
    A = A_1 \cup A_2 = \left\{ A_1, A_2 \right \} = \{ a_1, a_2, ..., a_{u} \}
\end{equation}



 
We can use recursion to arrive at a solution for $C(\bm{m})[k]$ by showing how to combine known solutions of $C(\bm{m})[k]$. If we are given two disjoint multisets $S_1$ and $S_2$ with respective multiplicities $\bm{m}_1$ and $\bm{m}_2$ and known combination count functions $C(\bm{m}_1)[k_1]$ and $C(\bm{m}_2)[k_2]$, we can calculate the combination count function $C(\bm{m})[k]$ where $\bm{m}$ is the multiplicity of the set $S$, the union of the two multisets.

To repeat, we are given $S_1$, $S_2$, $C(\bm{m}_1)[k_1]$ for any $k_1$, $C(\bm{m}_2)[k_2]$ for any $k_2$, and the knowledge that $S_1$ and $S_2$ are disjoint. We can derive $\bm{m}_1$, $\bm{m}_2$, $n_1$, $n_2$, $u_1$, $u_2$, $A_1$, and $A_2$ from $S_1$ and $S_2$, as shown previously.

Our new multiset $S$ is the union of the two source multisets.

\begin{equation}
    S = S_1 \uplus S_2
\end{equation}

\begin{equation}
    n = n_1 + n_2
\end{equation}

Our new item type set $A$ is the union, or concatenation, of the two source item type sets $A_1$ and $A_2$. Concatenation is equivalent to union in this special case because $S_1$ and $S_2$ (and therefore also $A_1$ and $A_2$) are disjoint.

\begin{equation}
    A_1 = \{ b_1, b_2, ..., b_{u_1}\}
\end{equation}

\begin{equation}
    A_2 = \{ c_1, c_2, ..., c_{u_1}\}
\end{equation}

\begin{equation}
    A = A_1 \cup A_2 = \left\{ A_1, A_2 \right \} = \{ a_1, a_2, ..., a_{u} \}
\end{equation}

\begin{equation}
    u = u_1 + u_2
\end{equation}

Here we restate the definition of the multiplicity $\bm{m}$ of $S$.

\begin{equation}
    \bm{m}[j] = \sum_{s \in S} \mathbbm{1}_{a_j}(s)
\end{equation} 

Because we are dealing with disjoint sets, we can split up the terms of $\bm{m}$.

\begin{equation}
    \bm{m}[j] = \sum_{s \in S} \mathbbm{1}_{a_j}(s) = \sum_{s \in S_1} \mathbbm{1}_{a_j}(s) + \sum_{s \in S_2} \mathbbm{1}_{a_j}(s)
\end{equation}

No element of $S_1$ is in $S$ with item type $a_j$ not in $A_1$, and no element of $S_2$ is in $S$ with item type $a_j$ not in $A_2$. We can therefore define the multiplicity as a piecewise function.

\begin{equation}
    \bm{m}[j] = \begin{cases} \sum_{s \in S_1} \mathbbm{1}_{a_j}(s) & j\leq n_1 \\  \sum_{s \in S_2} \mathbbm{1}_{a_j}(s) & \text{else} \end{cases} = \begin{cases} \sum_{s \in S_1} \mathbbm{1}_{b_{j}}(s) & j\leq n_1 \\  \sum_{s \in S_2} \mathbbm{1}_{c_{j - n_1}}(s) & \text{else} \end{cases}
\end{equation}

The top case is the definition of $\bm{m}_1$, and the second case is simply a shifted version of the definition of $\bm{m}_2$. 

\begin{equation}
    \bm{m}[j] = \begin{cases} \bm{m}_1[j] & j\leq n_1 \\  \bm{m}_2[j - n_1] & \text{else} \end{cases}
\end{equation}

In other words, when combining disjoint multisets, the resulting multiplicity is a simple concatenation of the two original multiplicities.

\begin{equation}
    \bm{m} = [\bm{m}_1, \bm{m}_2]
\end{equation}

This result will actually be relevant later. 

Now that we have combined the multiplicities, we would like to combine the combination counting functions. We again rely on the fact that $S_1$ and $S_2$ are disjoint. For each combination of $k$ items from $S$, $k_1 \in [0, k]$ items are from $S_1$ and $k_2\in [0, k]$ items are from $S_2$. 

\begin{equation}
    k = k_1 + k_2
\end{equation}

$C(\bm{m}_1)[k_1]$ and $C(\bm{m}_2)[k_2]$ are independent organizations; for each combination of items from $S_1$ counted by $C(\bm{m}_1)[k_1]$, there are exactly $C(\bm{m}_2)[k_2]$ combinations of the remaining items from $S_2$. For a given $k_1$, the count of combinations of $k$ items from $S$ is simply the product of the two known combination counts.

\begin{equation}
    C(\bm{m}; k_1)[k] = C(\bm{m}_1)[k_1] \cdot C(\bm{m}_2)[k_2] = C(\bm{m}_1)[k_1] \cdot C(\bm{m}_2)[k - k_1]
\end{equation}

No combination of $k$ items from $S$ with $k_1$ items from $S_1$ can be the same as a combination with a different number of $k_1$ items drawn from $S_1$. In other words, if we sum over all possible values of $k_1$, we will never avoid double count any combinations. As we stated above, for any combination of $k$ items, $k_1$ is at least $0$ and at most $k$. Therefore, the sum of the above equation over all values of $k_1$ exactly counts all combinations of $k$ items.

\begin{equation}
    C(\bm{m})[k] = \sum_{k_1 = 0}^{k} C(\bm{m}; k_1)[k] = \sum_{k_1 = 0}^{k} C(\bm{m}_1)[k_1] \cdot C(\bm{m}_2)[k - k_1]
\end{equation}

Since $C(\bm{m}_1)[k_1] = 0$ when $k_1 < 0$ and $C(\bm{m}_2)[k - k_1] = 0$ when $k_1 > 0$, we can make the sum infinite without affecting the value.

\begin{equation}
    C(\bm{m})[k] = \sum_{k_1 = -\infty}^{\infty} C(\bm{m}_1)[k_1] \cdot C(\bm{m}_2)[k - k_1]
\end{equation}

This is the convolution of the two functions. The convolution of two discrete functions $f[\cdot]$ and $g[\cdot]$ is represented as $(f * g)[\cdot]$.


\begin{equation}
     (f * g)[x] \equiv \sum_{\gamma=-\infty}^{\infty} f[\gamma]g[x - \gamma]
\end{equation}

\begin{equation}
    C(\bm{m})[k] = (C(\bm{m}_1) * C(\bm{m}_2))[k]
\end{equation}

To summarize, we have proved that when joining two disjoint multisets, the resulting multiplicity is a concatenation of the input multiplicities and the combination count is a convolution of the input combination counts.

\subsection{Generating Disjoint Submultisets}

In this section we will show how to do the reverse of the previous section. Specifically, if we can break up any multiset $S$ into two disjoint submultisets $S_1$ and $S_2$, then we can use the convolution result to calculate the desired combination count of the original multiset.

We start with two trivial cases. First, if $\bm{m}$ is empty, there is exactly one combination of $0$ items that can be selected from multiset $S$, and zero combinations of any other number of items.

\begin{equation}
    C([])[k] = \delta_0[k] = \begin{cases}1 & k = 0 \\ 0 & \text{else}  \end{cases}
\end{equation}

The second trivial case is where $\bm{m}$ has only one element. This is equivalent to the multiset $S$ having only one item type. Since $n$ is the number of items in the multiset, if $\bm{m}$ has only one element, it must be $n$. This is a pretty boring item group for a game because there is no randomness in selecting any number of items, but this simplicity means counting the possible combinations is relatively clear. If the entire multiset of $n$ items is composed of identical items, then there is exactly one combination of $k$ items if $k\leq n$ and exactly zero combinations otherwise.

\begin{equation}
    C([n])[k] = \Pi_n[k] = \begin{cases}1 & 0 \leq k \leq n \\ 0 & \text{else}  \end{cases}
\end{equation}

In the case that $\bm{m}$ is empty, $n=0$. If we relax our notation slightly, we can combine the solution in both trivial cases.

\begin{equation}
    \delta_0[k] = \begin{cases}1 & k = 0 \\ 0 & \text{else}  \end{cases} = \begin{cases}1 & 0 \leq k \leq 0 \\ 0 & \text{else}  \end{cases} = \Pi_0[k]
\end{equation}

\begin{equation}
    C(\bm{m})[k] = \Pi_n[k] = \begin{cases}1 & 0 \leq k \leq n \\ 0 & \text{else}  \end{cases}\text{ if } u\leq 1
\end{equation}

In all other cases, $\bm{m}$ has at least two elements. When this is the case, we can always break up $S$ into two disjoint submultisets $S_1$ and $S_2$. Let $S_1$ contain all copies of $a_1$, the first item type in the $A$, set of all item types in $S$. Let $S_2$ contain all the remaining items from $S$. The quantity of items of type $a_1$ is simply the first element of $\bm{m}$.

\begin{equation}
    S_1 = \{a_1 ^ {\bm{m}[1]}\} 
\end{equation}

The set of item types for $S_1$ has just the one element from $A$.

\begin{equation}
    A_1 = \{a_1\} = \{b_1\} = \{b_{u_1}\}
\end{equation}

\begin{equation}
    u_1 = 1
\end{equation}

$\bm{m}_1$ is a single element by design, making $S_1$ have the structure of the second trivial multiset type above.

\begin{equation}
    \bm{m}_1 = \bm{m}[1]
\end{equation}

$S_2$ is the remaining items in $S$.

\begin{equation}
    S_2 = S \setminus S_1
\end{equation}

$A_2$ is the remaining items in $S$, which is the same as the set of elements of $A$ after the first.

\begin{equation}
    A_2 = A \setminus A_1 = \{a_2, a_3, ..., a_u\} = \{c_1, c_2, ..., c_{u_2}\} 
\end{equation}

\begin{equation}
    u_2 = u - 1
\end{equation}

\begin{equation}
    \bm{m}_2 = [\bm{m}[2], \bm{m}[3], ..., \bm{m}[n]]
\end{equation}

We have shown how to create two disjoint submultisets from any non-trivial multiset, resulting in at least one trivial multiset. We can now recursively define a solution for $\bm{C}(\bm{m})$.

\begin{equation}
    \bm{C}(\bm{m}) = \begin{cases}
    \bm{C}(\varnothing) & \bm{m} = \varnothing \\
    \bm{C}([n]) & |\bm{m}| = 1 \\
    \left (\bm{C}([\bm{m}[1]]) * \bm{C}([[\bm{m}[2], \bm{m}[3], ..., \bm{m}[n]]]) \right ) & \text{else}
    \end{cases}
\end{equation}

\begin{equation}
    \bm{C}(\bm{m}) = \begin{cases}
    \bm{\delta}_0 & \bm{m} = \varnothing \\
    \bm{\Pi}_n & |\bm{m}| = 1 \\
    \left (\bm{\Pi}_{\bm{m}_ {1}} * \bm{C}([[\bm{m}[2], \bm{m}[3], ..., \bm{m}[n]]])\right ) & \text{else}
    \end{cases}
\end{equation}













\begin{equation}
    \bm{m}[j] = \begin{cases} \sum_{s \in S_1} \mathbbm{1}_{a_j}(s) & j\leq n_1 \\  \sum_{s \in S_2} \mathbbm{1}_{a_j}(s) & \text{else} \end{cases} = \begin{cases} \sum_{s \in S_1} \mathbbm{1}_{b_{j}}(s) & j\leq n_1 \\  \sum_{s \in S_2} \mathbbm{1}_{c_{j - n_1}}(s) & \text{else} \end{cases}
\end{equation}


split the full multiset $S$ with multiplicity $\bm{m}$ into two disjoint submultisets $S_1$ and $S_2$ with respective multiplicites $\bm{m}_1$ and $\bm{m}_2$.

\begin{equation}
    
\end{equation}


As with any discrete vector, we can divide $\bm{m}$ into $u$ delta functions $\bm{\rho}_i$, where each sub-characteristic frequency $\bm{\rho}_i$ represents the count in the full multiset $S$ of item type $a_i \in A$.

\begin{equation}
    \bm{\rho}_i = \bm{\delta}_{m(a_i)}
\end{equation}

\begin{equation}
    \bm{\rho} = \sum_{i = 1}^{u} \bm{\rho}_i = \sum_{i = 1}^{u} \bm{\delta}_{m(a_i)}
\end{equation}



Let $\bm{\rho}$ be the characteristic frequency of a multiset $S$. Any $\bm{\rho}$ with more than one unique type (i.e. $u>1$) can be divided into two characteristic frequencies representing two disjoint submultisets of $S$. Let $S_1$ and $S_2$ be disjoint subsets of $S$ with respective characteristic frequencies $\bm{\rho}_1$ and $\bm{\rho}_2$.

\begin{equation}
    S_1 \subset S
\end{equation}

\begin{equation}
    S_2 \subset S
\end{equation}

\begin{equation}
    \varnothing = S_1 \cap S_2
\end{equation}

\begin{equation}
    S = S_1 \uplus S_2
\end{equation}

Since $S_1$ and $S_2$ are disjoint, their 

\begin{equation}
    S = S_1 \uplus S_2
\end{equation}

\begin{equation}
    S = S_1 \uplus S_2
\end{equation}



\section{Examples}

\subsection{Scrabble}

\begin{equation}\nonumber
    S = \left \{
    \parbox{32em}{A, A, A, A, A, A, A, A, A, B, B, C, C, D, D, D, D, E, E, E, E, E, E, E, E, E, E, E, E, F, F, G, G, G, H, H, I, I, I, I, I, I, I, I, I, J, K, L, L, L, L, M, M, N, N, N, N, N, N, O, O, O, O, O, O, O, O, P, P, Q, R, R, R, R, R, R, S, S, S, S, T, T, T, T, T, T, U, U, U, U, V, V, W, W, X, Y, Y, Z, blank, blank}\right \}
\end{equation}

\begin{equation}\nonumber
    n = 100
\end{equation}

\begin{equation}\nonumber
    A = \left \{
    \parbox{32em}{A, B, C, D, E, E, F, G, H, I, J, K, L, M, N, O, P, Q, R, S, T, U, V, W, X, Y, Z, blank}\right \}
\end{equation}

\begin{equation}\nonumber
    u = 27
\end{equation}

\begin{equation}\nonumber
    r_{\max} = 12
\end{equation}

\begin{equation}\nonumber
    \bm{\rho} = [5, 10, 1, 4, 0, 3, 0, 1, 2, 0, 0, 1]
\end{equation}

\subsection{Hanabi}

\begin{equation}\nonumber
    S = \left \{\\
    \parbox{32em}{
     \color{magenta}1\color{black}, \color{magenta}1\color{black}, \color{magenta}1\color{black}, \color{magenta}2\color{black}, \color{magenta}2\color{black}, \color{magenta}3\color{black}, \color{magenta}3\color{black}, \color{magenta}4\color{black}, \color{magenta}4\color{black}, \color{magenta}5\color{black}, \color{green}1\color{black}, \color{green}1\color{black}, \color{green}1\color{black}, \color{green}2\color{black}, \color{green}2\color{black}, \color{green}3\color{black}, \color{green}3\color{black}, \color{green}4\color{black}, \color{green}4\color{black}, \color{green}5\color{black}, \color{blue}1\color{black}, \color{blue}1\color{black}, \color{blue}1\color{black}, \color{blue}2\color{black}, \color{blue}2\color{black}, \color{blue}3\color{black}, \color{blue}3\color{black}, \color{blue}4\color{black}, \color{blue}4\color{black}, \color{blue}5\color{black}, \color{yellow}1\color{black}, \color{yellow}1\color{black}, \color{yellow}1\color{black}, \color{yellow}2\color{black}, \color{yellow}2\color{black}, \color{yellow}3\color{black}, \color{yellow}3\color{black}, \color{yellow}4\color{black}, \color{yellow}4\color{black}, \color{yellow}5\color{black}, 1, 1, 1, 2, 2, 3, 3, 4, 4, 5
     }\right \}
\end{equation}

\begin{equation}\nonumber
    n = 50
\end{equation}

\begin{equation}\nonumber
    A = \left \{
     \color{magenta}1\color{black}, \color{magenta}2\color{black}, \color{magenta}3\color{black},  \color{magenta}4\color{black}, \color{magenta}5\color{black}, \color{green}1\color{black}, \color{green}2\color{black}, \color{green}3\color{black},  \color{green}4\color{black}, \color{green}5\color{black}, \color{blue}1\color{black}, \color{blue}2\color{black}, \color{blue}3\color{black}, \color{blue}4\color{black}, \color{blue}5\color{black}, \color{yellow}1\color{black}, \color{yellow}2\color{black},  \color{yellow}3\color{black}, \color{yellow}4\color{black}, \color{yellow}5\color{black}, 1, 2, 3, 4, 5\right \}
\end{equation}

\begin{equation}\nonumber
    u = 25
\end{equation}

\begin{equation}\nonumber
    r_{\max} = 3
\end{equation}

\begin{equation}\nonumber
    \bm{\rho} = [5, 15, 3]
\end{equation}

Hanabi is a multiplayer cooperative card game in which players hold their cards facing out. It is the opposite of traditional card games in that you can see everyone else's cards, but not your own. The goal is to play, discard, and give clues to other players such that cards are collectively played in a valid order on the table. There are some surprisingly complicated mathematically ideas involved in the game, perhaps not to play it casually, but certainly to even approach optimality.

We set out to solve two questions about probability and combinatorics that became important while coding strategies for a computer to play Hanabi. 

First, how many combinations of hands are possible? Since the validity of a clue in the game depends on the set of cards in your hand, not on their order, we consider specifically the number of combinations, not the number of permutations. The number of cards in a player's hand varies depending on the number of players and it is interesting to know the number of combinations of cards possible across all players' hands, so we would like an analytical formula for the number of combinations of any number of cards dealt from a Hanabi deck. Since the starting Hanabi deck itself changes across different game variants and the formula will be useful when the deck has been somewhat depleted during gameplay, we would like the formula to apply for any deck of cards. Note that the standard and variant Hanabi decks have repeated elements (e.g. there are three identical 1s of each color suit). We would like the analytical solution to lead to a fast, implementable algorithm.

Second, for an unknown card what is the conditional probability distribution given partial information about the card itself and partial information on other unknown cards from the same deck? In Hanabi, you give clues such as "This card is a 1" or "These two cards are Green". You therefore know positive information about some of the cards in your hand, as well as negative information about cards that were not clued (e.g. The other cards in my hand are \emph{not} 1s"). This is of course in addition to the knowledge during the game about the cards that are visible on the table, in the discard pile, and in other players' hands. It is therefore extremely useful to be able to calculate exactly the odds of any unknown card being any card type from the deck. This is useful whether the card in question is in your hand, in the deck, or even in someone else's hand if you pretended you couldn't see its value. Like the first question, we would like an analytical solution as well as a useful algorithm.

\setcounter{subsection}{-1}

\subsection{Notation}

Most of the notation that follows is standard and clear, but for reference here are some clarifications. Non-scalar values will be bold letters. Matrices will be bold, upper-case letters (e.g. $\bm{X}$). Vectors will be bold, lower-case letters (e.g. $\bm{x}$). Both matrices and vectors are 1-indexed by bracketed, non-bold scalars (e.g. $X[m, n]$).

$\mathbb{Z}_{+}$ is the set of positive integers. $\mathbb{Z}_{*}$ is the set of non-negative integers.

We use the indicator function denoted by $\mathbbm{1}_{(\cdot)}$.

\begin{equation}
    \mathbbm{1}_{A}(x) = \begin{cases} 
      1 & x\in A \\
      0 & \text{else}
   \end{cases}
\end{equation} 

We use the similar Dirac measure as a vector denoted by $\bm{\delta_{(\cdot)}}$.

\begin{equation}
    \delta_m[n] = \begin{cases} 
      1 & n=m \\
      0 & \text{else}
   \end{cases}
\end{equation} 

The discrete Heaviside or unit step function denoted by $H_{(\cdot)}$ will be useful, as will a modified rectangular function $\Pi_{(\cdot)}$.

\begin{equation}
    H_m[n] = \begin{cases} 
      1 & n\geq m \\
      0 & \text{else}
   \end{cases} = \sum_{i = -\infty}^{\infty} \delta_m[i]
\end{equation} 

\begin{equation}
    \Pi_m[n] = \begin{cases} 
      1 & 0\leq n \leq m \\
      0 & \text{else}
   \end{cases} = H_0[n] - H_m[n - 1]
\end{equation} 


\subsection{Deck Notation}

We need to represent the cards in a Hanabi deck before we continue. Let there be $N$ cards in a Hanabi deck. Each card has a color type (i.e. a suit) from a set of colors $A_\cap$ and a number value from a set of numbers $A_\#$.\footnote{We are using $\cap$ to represent the colors, or suits, in the Hanabi deck because it looks like a rainbow.} Let $N_\cap = \lvert A_\cap \rvert$ be the number of color types and $N_\# = \lvert A_\# \rvert$ be the number of number types.

Let the deck's card type matrix be $\bm{X}\in \mathbb{Z}_{*}^{N_\cap \times N_\#}$ where $X[m, n]$ is the number of cards with color type index $m\in [1, N_\cap]$ and number value index $n\in [1, N_\#]$. We can calculate some useful values from the card type matrix.

\begin{equation}
    N = \sum_{m = 1}^{N_\cap} \sum_{n = 1}^{N_\#}X[m, n]
\end{equation} 

Let $U$ be the number of unique card types in a deck. $U=N$ if and only if each card is unique.

\begin{equation}
    U = \sum_{m = 1}^{N_\cap} \sum_{n = 1}^{N_\#} \min(X[m, n]), 1) = \sum_{m = 1}^{N_\cap} \sum_{n = 1}^{N_\#} \mathbbm{1}_{\mathbb{Z}_{+}}(X[m, n])
\end{equation} 

Let $R$ represent the highest frequency of any card type in the deck. $R=1$ for a deck with unique cards. $R=N$ if there is only one card type in the entire deck.

\begin{equation}
    R = \max (\bm{X} )
\end{equation} 

 We define a characteristic frequency vector $\bm{\rho}\in \mathbb{Z}_{*}^{R}$ whose $r$th element is the number of distinct card types with $r$ cards in the deck. This is just a histogram of the card type matrix.
 
\begin{equation}
    \rho[r] = \sum_{m = 1}^{N_\cap} \sum_{n = 1}^{N_\#} \mathbbm{1}_{r}(X[m, n])
\end{equation} 
 
Note that we can still derive all relevant metrics from this frequency vector. In fact, we only need the characteristic frequency vector, not the full card type matrix, for some of the coming combinatorics.

\begin{equation}
    R = \lvert\bm{\rho}\rvert
\end{equation}

A more robust equation would be $R = \argmax_r{ \left ( r\mathbbm{1}_{>0}(\rho[r])\right )}$, but if we always truncate $\bm{\rho}$ to its last non-zero element, than the simpler equation above suffices.

\begin{equation}
    N = \sum_{r=1}^{R} r \rho[r]
\end{equation}

\begin{equation}
    U = \sum_{r=1}^{R} \rho[r]
\end{equation}

Note that we could represent a standard fifty-two card deck with this notation, even if our notation is a bit heavy for a deck with unique cards. 

\begin{equation}
A_\cap = \{\clubsuit, \diamondsuit, \heartsuit, \spadesuit\}, 
A_{\#} = \{2, 3, 4, ..., \text{Q}, \text{K}, \text{A}\}
\end{equation}

\begin{equation}
    \bm{X} = \begin{bmatrix} 1 & 1 & 1 & 1 & 1& 1 & 1 & 1 & 1& 1 &1 & 1 & 1\\1 & 1 & 1 & 1 & 1& 1 & 1 & 1 & 1& 1 & 1 & 1 & 1\\1 & 1 & 1 & 1 & 1& 1 & 1 & 1 & 1& 1 & 1 & 1 & 1\\1 & 1 & 1 & 1 & 1& 1 & 1 & 1 & 1& 1 & 1 & 1 & 1
\end{bmatrix}
\end{equation}

\begin{equation}
    \bm{\rho} = [52]
\end{equation}

\begin{equation}
R = 1, N = 52, U = 52
\end{equation}

More usefully, we can now specify the standard 50 card Hanabi deck using the subscript $_0$ to denote its associated representation.

\begin{equation}
A_{\cap_0} = \{\text{Red}, \text{Yellow}, \text{Green}, \text{Blue}, \text{White}\}, 
A_{\#_0} = \{1, 2, 3, 4, 5\}
\end{equation}

\begin{equation}
    \bm{X_0} = \begin{bmatrix} 3 & 2 & 2 & 2 & 1\\3 & 2 & 2 & 2 & 1\\3 & 2 & 2 & 2 & 1\\3 & 2 & 2 & 2 & 1\\3 & 2 & 2 & 2 & 1
\end{bmatrix}
\end{equation}

\begin{equation}
    \bm{\rho_0} = [5, 15, 5]^T
\end{equation}

\begin{equation}
R_0 = 3, N_0 = 50, U_0 = 25
\end{equation}

\section{Number of Combinations of $K$ Cards}

As stated in the introduction, we would like to know how many combinations of hands of any size are possible. Note that we are not yet concerned with order (permutations), but just with sets of cards (combinations). The smaller this number is, the less information is needed to communicate through Hanabi actions exactly which cards and in what quantity are in a player's hand. Fundamentally, we are solving a more general question that is applicable in not only Hanabi or standard card games, but also in Scrabble or Candyland where there are letter/card types of different frequencies.

Specifically, we are looking for an analytical solution for $C(\bm{\rho}, K)$, which we define to be the number of distinct combinations of $K$ items drawn without replacement from a set with characteristic frequency $\bm{\rho}$. Ideally, we solve for it in a form that allows for efficient computation.

\subsection{Monotype Decks}

As a first step, let's look at the simple case of having any number of copies of just one card type in our deck. Let $\bm{\rho_{\delta}}$ be the characteristic frequency of such a monotype deck, with $U_{\delta} = 1$ and $N_{\delta} = R_{\delta}$.\footnote{We use the $\delta$ notation because the characteristic frequency is a delta function.}

\begin{equation}
    \rho_{\delta}[r] = \delta_{R_{\delta}}[r] = \begin{cases} 
      1 & r=R_{\delta} \\
      0 & \text{else}
   \end{cases}
\end{equation}

An equation for $C(\bm{\rho_{\delta}}, K)$, the number of combinations of $K$ cards from a monotype deck with characteristic function $\bm{\rho_{\delta}}$, is fairly simple. If there are enough cards to deal $K$ cards from the deck, then the one and only possible hand is composed of copies of the same card. If there are not enough cards to deal $K$ cards, then there are no ways to deal a hand from the deck.

\begin{equation}
    C(\bm{\rho_{\delta}}, K) = 
    \Pi_{R_{\delta}}[K] = \begin{cases} 
      1 & 0\leq K \leq R_{\delta} \\
      0 & \text{else}
   \end{cases}
\end{equation}

There are not many interesting uses of monotype decks in games, exactly because there is no randomness. As a toy example, let's say you are dealing out the 4 \$100s to each of 6 players from the set of 20 \$100 bills in Monopoly. How many combinations of bills are there in total?

\begin{equation}
    C(\bm{\delta_{20}}, 24) = \Pi_{20}[24] = 0
\end{equation}

Uhoh, looks like you need to vote someone out of the game, get more monopoly \$100s, or start using some \$500s. That probably seemed like a trivial example but don't worry, the next section is more interesting, and we will actually use the above monotype deck result in our final solution for a general equation for $C(\bm{\rho}, K)$.

\subsection{No-Repetition Decks}

Now, let's look at the simple combinatorics if we had only distinct cards in our deck. Let $\bm{\rho_{.}}$ be any such deck. The binomial coefficient is exactly what we need in this situation to solve for $C(\bm{\rho_.}, K)$. The binomial coefficient or ``n choose k'' is the number of ways to choose $k$ items from $n$ unique options without replacement.

\begin{equation}
    \binom{n}{k} = \frac{n!}{k! (n - k)!}
\end{equation}

If we want to know the number of sets of $K$ cards from a deck of $N_.$ unique cards, we use the binomial coefficient formula.

\begin{equation}
    C(\bm{\rho_{.}}, K) = \binom{N_{.}}{K} = \frac{N_{.}!}{K! (N_{.}-K)!}
\end{equation}

For a standard deck of cards, we can use this result to already solve for the number of 5-card poker hands.

\begin{equation}
    C([52]^T, 5) = \binom{52}{5} = 2,598,960
\end{equation}

\subsection{Uniform-Repetition Decks}

We can get an analytical solution of $C(\bm{\rho}, K)$ for a more general deck type. Let $\bm{\rho_{\bot}}$ be any deck with card types that have the same frequency.\footnote{We are using the $\bot$ notation because it portrays the impulse function that is the characteristic frequency of a uniform-repetition deck.} We will call these decks uniform-repetition decks since all card types are repeated the same amount. Let $\bm{\rho_\bot}$ be the characteristic frequency of a deck with $U_\bot$ card types where all cards have the same frequency $R_\bot$.

\begin{equation}
    \bm{\rho_{\bot}} = U_{\bot} \bm{\delta_{R_{\bot}}}
\end{equation}

That is, $\bm{\rho_{\bot}}$ has just one non-zero element $U_\bot$ at index $R_{\bot}$.

\begin{equation}
    \rho_{\bot}[r] = U_{\bot} \delta_{R_{\bot}}[r] = \begin{cases} U_{\bot} & r=R_{\bot} \\ 0 & \text{else}
    \end{cases}
\end{equation}

Our goal is to count the number of combinations of $K$ cards from the full deck of $N_{\bot}$ cards. In the special case that $K\leq R_\bot$, we are never restricted by running out of any card type when dealing a hand; it is possible to have a hand entirely composed of a single card type. In this special case, the number of combinations is simply the number of combinations of card types with replacement.

The number of ways to select $k$ items from a set of $n$ items with replacement is described by the following formula in the ``$n$ multichoose $k$'' notation \cite{benjamin_quinn_2003}.

\begin{equation}
    \left (\binom{n}{k}\right) = \binom{n + k - 1}{k} = \frac{(n + k - 1)!}{(n - 1)!k!}
\end{equation}

We therefore have an analytical solution for the number of possible hands when all card types in the deck have the same frequency which is at least the number of cards being selected.

\begin{equation}
    C(\bm{\rho_{\bot}}, K) = \left (\binom{U_{\bot}}{K}\right) \text{ if } K \leq R_{\bot} = \frac{(U_{\bot} + K - 1)!}{(U_{\bot} - 1)!K!} \text{ if } K \leq R_{\bot}
\end{equation}

To avoid the constraint that $K\leq R_{\bot}$, we reformulate the problem in terms of compositions. Selecting $K$ items from $U_{\bot}$ options with replacement up to $R_\bot$ times is the same as trying to place $K$ items in exactly $U_{\bot}$ bins such that each bin has a count in the range $[0, R_{\bot}]$. Each count in a bin corresponds to a card of that type being selected.

Restricted compositions are usually discussed where each bin has a count in the range $[1, R]$. Luckily, the number of compositions of $K$ items into exactly $U$ bins where each bin has a non-negative item count is the same as the number of compositions of $K + U$ items into exactly $U$ bins where each bin has a count in the range $[1, R + 1]$. Let the number of compositions of $k$ items from a set of $n$ items each selected at most $w$ times be represented by $F(n, k, w)$ \cite{abramson}.

\begin{equation}
    F(n, k, w) = \sum_{j = 0}^k(-1)^j \binom{k}{j}\binom{n - jw - 1}{k - 1}
\end{equation}

We now have an analytical solution for the number of compositions of $K$ cards from a deck with uniform frequency $\bm{\rho_{\bot}}$ regardless of the number of cards being selected.

\begin{equation}
    C(\bm{\rho_\bot}, K) = F(K + U_\bot, U_\bot, R_\bot + 1)
\end{equation}

\begin{equation}
    C(\bm{\rho_\bot}, K) = \sum_{u = 0}^{U_\bot}(-1)^u \binom{U_\bot}{u}\binom{K + U_\bot - u(R_\bot + 1) - 1}{U_\bot - 1}
\end{equation}

Note that no-repetition decks are a subset of uniform-repetition decks, so this formula will work for any deck with only unique cards as well.

If we were playing a card game with the standard playing card deck, but suits did not matter, then each card type would have exactly 4 copies in the deck. We can now count the combinations of 5 cards from this uniform-repetition deck.

\begin{equation}
    C([0, 0, 0, 13]^T, 5) = \sum_{u = 0}^{13}(-1)^u \binom{13}{u}\binom{5 + 13 - u(4 + 1) - 1}{13 - 1}
\end{equation}

\begin{equation}
    C([0, 0, 0, 13]^T, 5) = 6,175
\end{equation}

\subsection{Variable-Repetition Decks}

Let $\bm{\rho}$ be the characteristic frequency of any deck. Just like with uniform-repetition decks, variable-repetition decks have a simple equation if the number of objects being selected is fewer than the number of copies of the rarest card type, since it is effectively selection with infinite replacement.

\begin{equation}
    C(\bm{\rho}, K) = \left (\binom{U}{K}\right) \text{ if } K \leq r_{\min}
\end{equation}

For an unconstrained solution, we can again turn to restricted compositions to calculate $C(\bm{\rho}, K)$. Selecting $K$ items from $U$ options with replacement up to $r_u$ times for option $u \in [1, U]$ is the same as trying to place $U + K$ items in exactly $U$ bins such that bin $u$ has a count in the range $[1, r_u + 1]$. Each count in a bin corresponds to a card of that type being selected. Let the number of compositions of $k$ items from a set of $n$ items each selected at most $w[i]$ times be represented by $G(n, k, \bm{w})$ \cite{abramson}.

\begin{equation}
    G(n, k, \bm{w}) = \binom{n - 1}{k - 1} - \sum_{j = 1}^k (-1)^j{\sum_{}^{}} ^*\binom{n - 1 - w[i_1] - w[i_2] - ... - w[i_j]}{k - 1}
\end{equation}

Where ${\sum_{}^{}} ^*$ is the sum over all combinations of $j$ indices $i_1<i_2<...<i_j$ such that $j \leq k$. This equation is hilariously complicated and extremely not closed form. I did implement it and it produces the correct results, but generating ordered combinations of elements is unfeasible even for small $k$. Nonetheless, this is our first analytical solution to $C(\bm{\rho}, K)$ that produces the correct result without placing constraints on the structure of our characteristic function. Let $\bm{x}$ be a vectorization of the non-zero elements of the card type matrix $\bm{X}$, and note that this vector can be derived from $\bm{\rho}$ through digitization (i.e. reverse histrogamming).

\begin{equation}
    C(\bm{\rho}, K) = G(K + U, U, \bm{x} + 1)
\end{equation}

\begin{equation}
    C(\bm{\rho}, K) = \binom{K + U - 1}{U - 1} - \sum_{j = 1}^U (-1)^j{\sum_{}^{}} ^*\binom{K + U - 1 - x[i_1] - x[i_2] - ... - x[i_j]}{U - 1}
\end{equation}

Again, where ${\sum_{}^{}} ^*$ is the sum over all combinations of $j$ indices $i_1<i_2<...<i_j$ such that $j \leq U$.

It is truly an abomination, but we can calculate a useful number of combinations. Let's say we are playing Pit, a game with 9 cards each of 7 different commodities, plus two special cards, the Bear and the Bull. You are dealt 9 cards at the start of the game. How many possible starting hands are there?

\begin{equation}
    C([2, 0, 0, 0, 0, 0, 0, 0, 7]^T, 9) = 12,727
\end{equation}

We have our solution, but we initially set out to find the number of combinations of hands in standard 4-player Hanabi. Unfortunately, the equation above is so slow when implemented, that it hasn't finished calculating this result.

\begin{equation}
    C(\bm{\rho_0}, 4) = ...?...
\end{equation}

The literature has let us down a bit in this case, but we can actually solve this problem through simpler math.

\subsection{Efficient Solution}

Let $\bm{\rho}$ be the characteristic function for any deck, and let $\bm{\rho_1}$ and $\bm{\rho_2}$ be disjoint subsets of this deck such that $\bm{\rho} = \bm{\rho_1} + \bm{\rho_2}$ (i.e. all cards from the original deck of the same card type are all either in subdeck 1 or subdeck 2). $C(\bm{\rho}, K)$, $C(\bm{\rho_1}, K_1)$ and $C(\bm{\rho_2}, K_2)$ are the number of combinations of $K$, $K_1$, and $K_2$ cards from each of these decks, respectively. Since our full deck is composed entirely of cards from either subdeck, $K = K_1 + K_2$. We are interested in solving for $C(\bm{\rho}, K)$ in terms of $C(\bm{\rho_1}, K_1)$ and $C(\bm{\rho_2}, K_2)$. 

Let $C(\bm{\rho}, K; K_1)$ be the combinations of $K$ cards from the full deck given that there are exactly $K_1$ cards from the first subdeck. There are $C(\bm{\rho_1}, K_1)$ combinations of $K_1$ cards from the first subdeck, and for each of these arrangements, there are exactly the same $C(\bm{\rho_2}, K - K_1)$ arrangements of $K - K_1$ cards from the second deck. It is important that the two subdecks contain entirely distinct card types, or this would not be true.

\begin{equation}
    C(\bm{\rho}, K; K_1) = C(\bm{\rho_1}, K_1 ; K_1) C(\bm{\rho_2}, K_2; K_1)= C(\bm{\rho_1}, K_1) C(\bm{\rho_2}, K - K_1)
\end{equation}

Of course, for any $K$, $K_1$ can be anything in the range $[0, K]$. These count distinct arrangements, since no hand made of $K_a$ cards from a subdeck can ever be the same as any hand made of $K_b$ cards from the same subdeck if $K_a \ne K_b$. Again, it is important that the two subdecks contain entirely distinct card types, or this would not be true. Therefore, we just need to sum all combinations with $K_1$ cards from the first subdeck and $K - K_1$ cards from the second subdeck over all values of $K_1$.

\begin{equation}
    C(\bm{\rho}, K) = \sum_{k_1=0}^K C(\bm{\rho}, K; k_1) = \sum_{k_1=0}^K C(\bm{\rho_1}, k_1) C(\bm{\rho_2}, K - k_1)
\end{equation}

This is exactly the convolution of the two combination-counting functions, where below is the definition of the discrete convolution.

\begin{equation}
     (f * g)[x] \equiv \sum_{\gamma=-\infty}^{\infty} f[\gamma]g[x - \gamma]
\end{equation}

\begin{equation}
    C(\bm{\rho}, K) = (C(\bm{\rho_1}, \cdot) * C(\bm{\rho_2}, \cdot))[K]
\end{equation}

Since any deck with more than one card type can be recursively divided into two distinct subdecks with no cards of the same type, we can repeatedly apply this method. Let $\bm{\rho_{s}}$ be the characteristic frequency of any set of $S$ disjoint subdecks of $\bm{\rho}$.

\begin{equation}
    \bm{\rho} = \sum_{s = 1}^{S} \bm{\rho_{s}}
\end{equation}

We can then accumulate the number of combinations one subdeck at a time.

\begin{equation}
    C(\bm{\rho}, K) = (C(\bm{\rho_{1}}, \cdot) * (C(\bm{\rho_{2}},\cdot) * ... * (C(\bm{\rho_{S}}, \cdot))...))[K]
\end{equation}

Convolution is linear, and therefore associative.

\begin{equation}
    C(\bm{\rho}, K) = (C(\bm{\rho_{1}}, \cdot) * C(\bm{\rho_{2}},\cdot) * ... * C(\bm{\rho_{S}}, \cdot)) [K]
\end{equation}

And we can simplify the notation

\begin{equation}
    C(\bm{\rho}, K) =  \left (\Conv_{s = 1}^S C(\bm{\rho_{s}}, \cdot)\right )[K]
\end{equation}

This is much more elegant than our previous solution for decks with arbitrary structure. More importantly, it is combinatorially faster since it does not have to enumerate lists of indices.

There are obviously numerous ways to create disjoint subdecks from a single deck. One simple method is to simply create $U$ subdecks, each with all the cards of just that one unique card type. For a standard deck of Hanabi, this would mean splitting the deck into a deck with all the red 1s, another with all the green 1s, another with just the blue 5, etc. Each of these subdecks is a monotype deck, for which we know the number of combinations of $K$ cards.

Let any deck $\bm{\rho}$ have $S$ subdecks $\bm{\rho_{s_\delta}}$ such that $\max_{s}\max_{r}\rho_{s_\delta}[r] = 1$ (i.e. each subdeck is a monotype deck with just one unique card type) and $\bm{\rho} = \sum_{s = 1}^S \bm{\rho_{s_{\delta}}}$ (i.e. the subdecks are disjoint and the original deck is composed entirely of the set of disjoint subdecks). Let subdeck $\bm{\rho_{s_{\delta}}}$ have a distinct card type with frequency $R_s$. The number of combinations of $K$ cards from the original deck is a convolution of the possible combinations of cards from each subdeck.

\begin{equation}
    C(\bm{\rho}, K) =  \left (\Conv_{s = 1}^S C(\bm{\rho_{s_{\delta}}}, \cdot)\right )[K]
\end{equation}

\begin{equation}
    C(\bm{\rho}, K) =  \left (\Conv_{s = 1}^S \Pi_{R_{s}}\right )[K]
\end{equation}

Perhaps this is not the most useful formulation for intuition, but its implementation is extremely fast as it is just the convolution of $S$ rectangular functions. Note that this formula is correct for any type of deck representable by a characteristic frequency $\bm{\rho}$.

\subsection{Conclusion}

We can finally get an answer to our original question, as well as others. How many hands are possible in a standard 4-player game of Hanabi?

\begin{equation}
    C(\bm{\rho_0}, 4) = 18,480
\end{equation}

What about the number of combinations of 20 cards dealt to the 5 players in a full-rainbow game of Hanabi?

\begin{equation}
    C([6, 18, 6]^T, 20) = 823,462,074,396
\end{equation}

How about the combinations of starting tiles in a game of Scrabble?

\begin{equation}
    C([5, 10, 1, 4, 3, 1, 2, 1]^T, 7) = 3,199,645
\end{equation}

\section{Conditional Card Distributions}

\pagebreak

\section{Appendix}

\begin{equation}
    C(\bm{\rho_{\bot}}, K) = \frac{(U_{\bot} + K - 1)!}{(U_{\bot} - 1)!K!} \text{ if } K \leq R_{\bot}
\end{equation}
\begin{equation}
    C(\bm{\rho_{\cdot}}, 1) = \frac{(U_{\bot} + 1 - 1)!}{(U_{\bot} - 1)!1!} = U_{\bot}
\end{equation}

\begin{equation}
    C(\bm{\rho_{\cdot}}, 1) = U
\end{equation}


\begin{equation}
    d(k) = \begin{cases} 
      -\mathds{1} & k=1 \\
      \sum_{k=1}^K \rho[k]* & n>1
   \end{cases}
\end{equation}

\begin{equation}
    f(n-1, \bm{\rho}_1^K) = \begin{cases} 
      \sum_{k=1}^K \rho_k & n=1 \\
      \rho_1*f(n - 1, [\rho_1 - 1, \bm{\rho}_2^K]) + \sum_{k=2}^K \rho_k*f(n - 1, [\bm{\rho}_1^{k-1} + 1, \rho_k - 1, \bm{\rho}_{k+1}^K]) & n>1
   \end{cases}
\end{equation}

\begin{equation}
    f(N, M, \bm{\rho}) = \begin{cases} 
      1 & N=0 \text{ or } N=M \\
      \sum_{k=\max (0, \sum \bm{\rho}_1^{M-1})}^{\min(\rho_0, N)}f(N - \rho_0, M - 1, \bm{\rho}_1^{M-1}) & \text{else}
   \end{cases}
\end{equation}
\section{Backup}



We can use this simple result already to bound the possible combinations of Hanabi hands. Adding cards to a deck, whether unique or repeated, can never decrease the number of possible hands. Also, more card type repetition for the same size deck leads to fewer possible hands, all the way down to one possible hand of $K \leq N$ cards and no possible hands of $K > N$ cards if all the cards are identical.  We can bound $C(\bm{\rho}, K)$ from below by allowing only one of each unique card type and from above by considering all cards to be unique. This works from below because going from the lower bounding deck to the true deck involves adding cards, and therefore never decreases the number of combinations. This works from above because going from the higher bounding deck to the true deck involves increasing card type repetition, and therefore never increases the number of combinations.

\begin{equation}
    \binom{U}{K} \leq C(\bm{\rho}, K) \leq \binom{N}{K} 
\end{equation}

Remember that we can derive all relevant deck information from $\bm{\rho}$.

\begin{equation}
    \binom{\sum_{r=1}^{\lvert \bm{\rho}\rvert} \rho[r]}{K} \leq C(\bm{\rho}, K) \leq \binom{\sum_{r=1}^{\lvert\bm{\rho}\rvert} r \rho[r]}{K} 
\end{equation} 

Note that the bounds are tight if and only if all cards are unique (i.e. $\bm{\rho}=[N]$ and so $U=N$). 


One useful quantity we still hope to compute is the number of possible 4 card hands dealt from the standard Hanabi deck.

\begin{equation}
    \binom{25}{4} \leq C(\bm{\rho_0}, 4) \leq \binom{50}{4} 
\end{equation}

\begin{equation}
    12,650 \leq C(\bm{\rho_0}, 4) \leq 230,300 
\end{equation}

What about the total combinations of cards dealt in a full-rainbow, 5-player game?

\begin{equation}
    \bm{\rho_R} = [6, 18, 6]^T
\end{equation}

\begin{equation}
    30,045,015 \leq C(\bm{\rho_R}, 20) \leq 4,191,844,505,805,495
\end{equation}

Clearly, we could use some tighter bounds or, even better, an analytical solution for $C(\bm{\rho}, K)$ when there are non-unique cards.


In the last section, we solved for $C(\bm{\rho}, K)$ if $\lvert \bm{\rho} \rvert=1$ and used the result to bound the solution for any $\bm{\rho}$. In this section, we will do something very similar. Instead of restricting our decks to no-repetition decks, we will restrict our decks to have card types that are all equally repeated. Let $\bm{\rho_\bot}$ be the card frequency of a deck with $U_\bot$ card types where all cards have the same frequency $R_\bot$.\footnote{We are using the $\bot$ notation because it portrays the impulse function that is the characteristic frequency of a uniform-repetition deck.}

\begin{equation}
    \bm{\rho_{\bot}} = U_{\bot} \bm{\delta_{R_{\bot}}}
\end{equation}

That is, $\bm{\rho_{\bot}}$ has just one non-zero element $U_\bot$ at index $R_{\bot}$.

\begin{equation}
    \rho_{\bot}[r] = U_{\bot} \delta_{R_{\bot}}[r] = \begin{cases} U_{\bot} & r=R_{\bot} \\ 0 & \text{else}
    \end{cases}
\end{equation}

Our goal is to count the number of combinations of $K$ cards from the full deck of $N_{\bot}$ cards. In the special case that $K\leq R_\bot$, we are never restricted by running out of any card type when dealing a hand; it is possible to have a hand entirely composed of a single card type. In this special case, the number of combinations is simply the number of combinations of card types with replacement.

The number of ways to select $k$ items from a set of $n$ items with replacement is described by the following formula in the ``$n$ multichoose $k$'' notation \cite{benjamin_quinn_2003}.

\begin{equation}
    \left (\binom{n}{k}\right) = \binom{n + k - 1}{k} = \frac{(n + k - 1)!}{(n - 1)!k!}
\end{equation}

We therefore have an analytical solution for the number of possible hands when all card types in the deck have the same frequency which is at least the number of cards being selected.

\begin{equation}
    C(\bm{\rho_{\bot}}, K) = \left (\binom{U_{\bot}}{K}\right) \text{ if } K \leq R_{\bot} = \frac{(U_{\bot} + K - 1)!}{(U_{\bot} - 1)!K!} \text{ if } K \leq R_{\bot}
\end{equation}

To avoid the constraint that $K\leq R_{\bot}$, we reformulate the problem in terms of compositions. Selecting $K$ items from $U_{\bot}$ options with replacement up to $R_\bot$ times is the same as trying to place $K$ items in exactly $U_{\bot}$ bins such that each bin has a count in the range $[0, R_{\bot}]$. Each count in a bin corresponds to a card of that type being selected.

Restricted compositions are usually discussed where each bin has a count in the range $[1, R]$. Luckily, the number of compositions of $K$ items into exactly $U$ bins where each bin has a non-negative item count is the same as the number of compositions of $K + U$ items into exactly $U$ bins where each bin has a count in the range $[1, R + 1]$. Let this number be represented by $F(n, k, w)$ to match combinatoric notation where $n = K + U$, $k = U$, and $w = R + 1$ for our uses \cite{abramson}.

\begin{equation}
    F(n, k, w) = \sum_{j = 0}^k(-1)^j \binom{k}{j}\binom{n - jw - 1}{k - 1}
\end{equation}

We now have an analytical solution for the number of compositions of $K$ cards from a deck with uniform frequency $\bm{\rho_{\bot}}$ regardless of the number of cards being selected.

\begin{equation}
    C(\bm{\rho_\bot}, K) = F(K + U_\bot, U_\bot, R_\bot + 1)
\end{equation}

\begin{equation}
    C(\bm{\rho_\bot}, K) = \sum_{u = 0}^{U_\bot}(-1)^u \binom{U_\bot}{u}\binom{K + U_\bot - u(R_\bot + 1) - 1}{U_\bot - 1}
\end{equation}

We can improve our bounds from the last section by using this result. We start by defining an operation that never decreases the number of possible combinations of any number of cards from a deck with frequency $\bm{\rho}$. Let $r_<$ be a card type frequencies. Replacing $u$ card types of frequency $r_<$ with $u$ card types of frequency $\hat{r}$ will never decrease the number of possible combinations. This operation adds more cards to the deck while maintaining the number of unique card types, so it should be obvious that this cannot reduce the possible combinations. In fact, the number of combinations is only not increased by this operation if $K \leq r_<$, so the additional repeated cards are irrelevant.

\begin{equation}
    \rho_{N+}[r] = \Delta_{N+}(\bm{\rho}, \hat{r}, r_<, u)[r] = \begin{cases} 
      \rho[r] - u & r=r_< \\
      \rho[r] + u & r=\hat{r} \\
      \rho[r] & \text{else} 
   \end{cases}
\end{equation}

Recall that $R$ is the highest frequency of any single card type in the deck. The operation $\Delta_{N+}(\bm{\rho}, R, r_<, u)$ adds $R - r_<$ cards to $u$ card types with frequency $r_<$ until they have the same frequency as the most repeated card already in the deck. We can repeatedly apply this operation until all card types to have the same frequency $R$. The final result will be a uniform-repetition deck with at least as many combinations for any $K$ as the original deck.

\begin{equation}
    \rho_{\bot_+}[r] = \Delta_{\bot_+}(\bm{\rho})[r]  = \mathbbm{1}_{R}(r) \left (\sum_{s=1}^{R - 1} \rho[s] +\rho[R] \right )
\end{equation}

This operation has an analogous ones for reducing the total number of combinations. We can reduce possible combinations by removing cards of card types with a high frequency. This maintains the number of unique cards in the deck while reducing the size of the deck. 

\begin{equation}
    \rho_{N-}[r] = \Delta_{N-}(\bm{\rho}, \hat{r}, r_>, u)[r]  = \begin{cases} 
      \rho[r] + u & r=\hat{r} \\
      \rho[r] - u & r=r_> \\
      \rho[r] & \text{else} 
   \end{cases}
\end{equation}

And we can again apply this operation repeatedly until we have a uniform-repetition deck with at most the same number of possible combinations. Let $r_{\min}$ be the first non-zero element of $\bm{\rho}$ (i.e. the frequency of the card type with the fewest cards).

\begin{equation}
    \rho_{\bot_-}[r] = \Delta_{\bot_-}(\bm{\rho})[r]  = \mathbbm{1}_{r_{\min}}(r) \left (\rho[r_{\min}] + \sum_{s=r_{\min}+1}^{R} \rho[s] \right )
\end{equation}

We now have new bounds on our desired quantity of combinations.

\begin{equation}
    C(\bm{\Delta_{\bot_-}}(\bm{\rho}), K) \leq C(\bm{\rho}, K) \leq C(\bm{\Delta_{\bot_+}}(\bm{\rho}), K)
\end{equation}

\begin{equation}
    F(K + U_{\bot_-}, U_{\bot_-}, R_{\bot_-} + 1) \leq C(\bm{\rho}, K) \leq F(K + U_{\bot_+}, U_{\bot_+}, R_{\bot_+} + 1)
\end{equation}

Note that our operations don't change the number of unique card types, so $U_{\bot_-} = U = U_{\bot_+}$. Also, $R_{\bot_-} = r_{\min}$ and $R_{\bot_+} = R$.

\begin{equation}
    F(K + U, U, r_{\min} + 1) \leq C(\bm{\rho}, K) \leq F(K + U, U, R + 1)
\end{equation}

We can tighten our bounds on those previous values of interest.

\begin{equation}
    12,650 \leq C(\bm{\rho_0}, 4) \leq 20,450
\end{equation}

\begin{equation}
    30,045,015 \leq C(\bm{\rho_R}, 20) \leq 12,159,022,256,370
\end{equation}

Yes, those pesky lower bounds haven't improved at all since the previous section, but they are actually tighter using this method for any distribution of card frequencies that have $r_{\min}>1$. We can do better still, though!



Let $\bm{\rho}$ be the card type frequency of any deck, and let $\bm{\rho_1}$ and $\bm{\rho_2}$ be disjoint subsets of this deck such that $\bm{\rho} = \bm{\rho_1} + \bm{\rho_2}$. $C(\bm{\rho}, K)$, $C(\bm{\rho_1}, K_1)$ and $C(\bm{\rho_2}, K_2)$ are the number of combinations of $K$, $K_1$, and $K_2$ cards from each of these decks, respectively. Since our full deck is composed entirely of cards from either subdeck, $K = K_1 + K_2$. We are interested in solving for $C(\bm{\rho}, K)$ in terms of $C(\bm{\rho_1}, K_1)$ and $C(\bm{\rho_2}, K_2)$. 

Let $C(\bm{\rho}, K; K_1)$ be the combinations of $K$ cards from the full deck given that there are exactly $K_1$ cards from the first subdeck. There are $C(\bm{\rho_1}, K_1)$ of arranging the $K_1$ cards from the first subdeck, and for each of these arrangements, there are exactly the same $C(\bm{\rho_2}, K - K_1)$ arrangements of $K - K_1$ cards from the second deck. It is important that the two subdecks contain entirely distinct card types, or this would not be true.

\begin{equation}
    C(\bm{\rho}, K; K_1) = C(\bm{\rho_1}, K_1 ; K_1) C(\bm{\rho_2}, K_2; K_1)= C(\bm{\rho_1}, K_1) C(\bm{\rho_2}, K - K_1)
\end{equation}

Of course, for any $K$, $K_1$ can be anything in the range $[0, K]$. These count distinct arrangements, since no hand made of $K_a$ cards from a subdeck can ever be the same as any hand made of $K_b$ cards from the same subdeck if $K_a \ne K_b$. Again, it is important that the two subdecks contain entirely distinct card types, or this would not be true. Therefore, we just need to sum all combinations with $K_1$ cards from the first deck over all values of $K_1$.

\begin{equation}
    C(\bm{\rho}, K) = \sum_{k_1=0}^K C(\bm{\rho}, K; k_1) = \sum_{k_1=0}^K C(\bm{\rho_1}, k_1) C(\bm{\rho_2}, K - k_1)
\end{equation}

This is exactly the convolution of the two combinations functions. 
\begin{equation}
     (f * g)[x] \equiv \sum_{\gamma=-\infty}^{\infty} f[\gamma]g[x - \gamma]
\end{equation}

\begin{equation}
    C(\bm{\rho}, K) = (C(\bm{\rho_1}, \cdot) * C(\bm{\rho_2}, \cdot))[K]
\end{equation}

Since any deck can be repeatedly divided in to two distinct subdecks with no cards of the same type, we can repeatedly apply this method. Let $\bm{\rho_{s}} \in \mathbb{Z}_{+}^R$ be the card type frequency of any set of $S$ disjoint subdecks of $\bm{\rho}$.

\begin{equation}
    \bm{\rho} = \sum_{s = 1}^{S} \bm{\rho_{s}}
\end{equation}

We can then accumulate the number of combinations one subdeck at a time.

\begin{equation}
    C(\bm{\rho}, K) = (C(\bm{\rho_{1}}, K) * (C(\bm{\rho_{2}},K) * ... * (C(\bm{\rho_{S}}, K))...))[K]
\end{equation}

Convolution is linear, and therefore associative.

\begin{equation}
    C(\bm{\rho}, K) = (C(\bm{\rho_{1}}, K) * C(\bm{\rho_{2}},K) * ... * C(\bm{\rho_{S}}, K)) [K]
\end{equation}

\begin{equation}
    C(\bm{\rho}, K) =  (\Conv_{s = 1}^S C(\bm{\rho_{s}}, K))[K]
\end{equation}

A deck with card types in different quantities can be thought of as a group of many decks, each with all card types of the same quantities. Imagine splitting the standard Hanabi deck into three - one with just the 5s, one with the duplicate 2s, 3s, and 4s, and one with the triplicate 3s.

\begin{equation}
    \bm{\rho} = \sum_{r = 1}^{R} \rho_{\bot_r} = \sum_{r = 1}^{R} U_{\bot_r} \bm{\delta_r}
\end{equation}

Since we can calculate the combinations of $K$ cards from cards of uniform-repetition, this decomposition of any deck into many decks with uniform-repetition is very useful. Let's examine what happens when we split any deck into two sub-decks.


\bibliographystyle{plain}
\bibliography{references}
\end{document}
